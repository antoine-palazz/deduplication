{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ffef94-6bdc-4755-b63f-a9d37de5b487",
   "metadata": {},
   "source": [
    "# OJA Deduplication Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd688565-deed-4585-a0ee-df0d4ec05a21",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb78e8-4f53-4270-a8b4-741d8f2c0b61",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6c7865-e3c1-4965-8bb5-7a6a60278116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81af9666-2fea-48af-8e94-080099027bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d5b862-14be-4b4a-b483-99acb9aa32af",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91198bd1-39c3-4757-8116-f482e34efff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import from s3\n",
    "os.system(f\"mc cp s3/apalazzolo/Deduplication/wi_dataset.csv wi_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd17c6a-d756-4f6c-a68a-6e54de7da6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('wi_dataset.csv',\n",
    "                   lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c5376-0970-4f41-85a5-d4368d0ea36b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For now let's work with a smaller extract\n",
    "\n",
    "# data = data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5dfc93-bc75-4fd4-b4fe-98398b8116a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_ads = len(data)\n",
    "n_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c010e8-8869-4cd3-8604-b9572edfff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cdd05-817f-4b3b-951d-78748a0dc5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76029d4c-fcb2-42aa-9057-1293f71f5122",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a06be7b-e6a8-44ca-8f28-5c80380140a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic cleaning\n",
    "\n",
    "data.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a9f1c-62f4-4490-9fb8-c46a3f8143af",
   "metadata": {},
   "source": [
    "## Naive deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4194a-7f17-4c57-ae6f-7f3ccbc9be44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0ace7-81fe-49cb-8205-8b3c199e11c4",
   "metadata": {},
   "source": [
    "### Add the full duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa306830-a995-4086-b7a9-fe51fd61316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['title', 'description', 'id', 'company_name', 'location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500983f6-287f-4909-83dc-a6253b3177e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(n_ads-1)):\n",
    "    j = i+1\n",
    "    while j < n_ads and data.iloc[j, 1] == data.iloc[i, 1] and data.iloc[j, 2] == data.iloc[i, 2]:\n",
    "        # if data.iloc[j, 5] == data.iloc[i, 5] or len(data.iloc[i, 5]) * len(data.iloc[j, 5]) == 0:\n",
    "            # if data.iloc[j, 3] == data.iloc[i, 3] or len(data.iloc[i, 3]) * len(data.iloc[j, 3]) == 0:\n",
    "        duplicates.append({'id1': data.iloc[i, 0], 'id2': data.iloc[j, 0], 'type': 'FULL'})\n",
    "        j += 1\n",
    "\n",
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5714b3-b472-4800-914f-13543f877684",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550e345-c226-4ded-b16f-1c5ad583f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c6b25-6261-4d00-9a7b-d6afdaeed26f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add the semantic duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c2d5c-d2e9-4ea0-9da1-fddd262f4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\n",
    "    ['title', 'description', 'location', 'country_id', 'company_name']\n",
    "] = data[\n",
    "    ['title', 'description', 'location', 'country_id', 'company_name']\n",
    "].progress_apply(lambda x: x.str.replace(r'\\W', ' ').apply(lambda x: unidecode(re.sub(' +', ' ', x))).str.strip().str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07152c-d2bc-4d8c-aa45-87b8782bcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b18aff-8339-49a2-b5fa-70f15fad2bb9",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c1272-a34d-42af-bd78-12b8d3927346",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stopwords_list = stopwords.words(\n",
    "    'danish') + stopwords.words(\n",
    "    'dutch') + stopwords.words(\n",
    "    'english') + stopwords.words(\n",
    "    'finnish') + stopwords.words(\n",
    "    'french') + stopwords.words(\n",
    "    'german') + stopwords.words(\n",
    "    'hungarian') + stopwords.words(\n",
    "    'portuguese') + stopwords.words(\n",
    "    'romanian') + stopwords.words(\n",
    "    'russian') + stopwords.words(\n",
    "    'spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef9092-0b63-4970-8f8e-3910461df66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['text'] = data['title'] + ' ' + data['location'] + ' ' + data['country_id'] + ' ' + data['company_name'] + ' ' + data['description']\n",
    "\n",
    "# Lemmatiser les mots\n",
    "lem = WordNetLemmatizer()\n",
    "data['filtered_text'] = data['text'].progress_apply(lambda x: ' '.join([lem.lemmatize(word) for word in x.split() if word not in final_stopwords_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fe69e-c712-44e0-bcf9-d4d77206295d",
   "metadata": {},
   "source": [
    "#### Tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4bd34-8811-499d-aaf9-876d2f57c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le tokenizer et le modÃ¨le BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98879f41-4fca-4152-b283-1d3d6f3866a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les textes avec BERT\n",
    "def encode_text(text):\n",
    "    input_ids = torch.tensor(tokenizer.encode(text, add_special_tokens=True, truncation=True)).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    return last_hidden_state[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4f31d-9e91-4880-bb7c-17719420bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = data['filtered_text'].progress_apply(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ee877-4dc8-4594-93bb-7c7edb83dcc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix_bert = [list(x) for x in bert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec3f227-de13-4b96-aa81-b8c0bd331962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_by_chunk(start, end):\n",
    "    if end > n_ads:\n",
    "        end = n_ads\n",
    "    return cosine_similarity(X=matrix_bert[start:end], Y=matrix_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d4960-89af-4f83-80dc-bbdc58dcbdb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 10000\n",
    "\n",
    "for chunk_start in range(0, n_ads, chunk_size):\n",
    "    similarity_matrix_chunk = cosine_similarity_by_chunk(chunk_start, chunk_start+chunk_size)\n",
    "    compteur_init = len(duplicates)\n",
    "    for i in tqdm(range(chunk_size)):\n",
    "        for j in range(chunk_start+i+1, n_ads):\n",
    "            if similarity_matrix_chunk[i][j] > 0.996:\n",
    "                if abs(\n",
    "                    len(data.iloc[chunk_start+i, 2]) - len(data.iloc[j, 2])\n",
    "                ) / (1 + min(\n",
    "                    len(data.iloc[chunk_start+i, 2]), len(data.iloc[j, 2])\n",
    "                )) > 0.1:\n",
    "                    duplicates.append({'id1': data.iloc[chunk_start+i, 0], 'id2': data.iloc[j, 0], 'type': 'PARTIAL'})\n",
    "                elif data.iloc[chunk_start+i, 6] != data.iloc[j, 6]:\n",
    "                    duplicates.append({'id1': data.iloc[chunk_start+i, 0], 'id2': data.iloc[j, 0], 'type': 'TEMPORAL'})\n",
    "                else:\n",
    "                    duplicates.append({'id1': data.iloc[chunk_start+i, 0], 'id2': data.iloc[j, 0], 'type': 'SEMANTIC'})\n",
    "    compteur_end = len(duplicates)\n",
    "    print(compteur_end-compteur_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e7a47-7cd1-4156-a58a-2e4ec47968a2",
   "metadata": {},
   "source": [
    "## Print duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b97a86-8af2-43ce-9d82-2fa03fe354aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicates = pd.DataFrame(duplicates)\n",
    "duplicates.sort_values(by=['type'], inplace=True)\n",
    "duplicates.drop_duplicates(subset=['id1', 'id2'], inplace=True)\n",
    "duplicates.sort_values(by=['id1', 'id2'], inplace=True)\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c8bb75-28c8-46e8-b56d-670b6a3715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicates) - len(duplicates.drop_duplicates(subset=['id1', 'id2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29eca5-57fc-4177-88f5-fb54bff7d030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicates[duplicates['id1'] > duplicates['id2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ada46bb-8f0b-4f1a-836d-480fab2fc4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "duplicates.groupby('type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ff259-1029-40b4-983e-4b5065634015",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates.to_csv('duplicates.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaa345-d5f1-4c63-8918-bbcbae734a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.system(f\"mc cp duplicates.csv s3/apalazzolo/Deduplication/duplicates_bert.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d048c-e4f5-425e-8daa-eb66d3cf7340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
